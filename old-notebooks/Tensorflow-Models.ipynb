{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "cmap = plt.cm.tab10\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../dataset/german_credit_data_withrisk.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    new_col = col.replace(\" \", \"_\")\n",
    "    if col != new_col:\n",
    "        data[new_col] = data[col]\n",
    "        del data[col]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_impute = \"mean\" # One of [\"mean\", \"zero\", \"infinity\"]\n",
    "cat_impute = \"mode\" # One of [\"mode\", \"none\"]\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_index2word = {\n",
    "    0: \"unskilled and non-resident\", \n",
    "    1: \"unskilled and resident\", \n",
    "    2: \"skilled\", \n",
    "    3: \"highly skilled\"\n",
    "}\n",
    "def assign_job_type(col):\n",
    "    return job_index2word[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Job = data.Job.apply(assign_job_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Sex', 'Job', 'Housing', 'Saving_accounts', 'Checking_account', 'Purpose']\n",
    "num_cols = ['Age', 'Credit_amount', 'Duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_with_mean(df):\n",
    "    out = pd.DataFrame(df)\n",
    "    for col in df.columns:\n",
    "        if col in num_cols:\n",
    "            out.loc[out[col].isna(), col] = df[col].mean()\n",
    "    return out\n",
    "def impute_with_zero(df):\n",
    "    out = pd.DataFrame(df)\n",
    "    for col in df.columns:\n",
    "        if col in num_cols:\n",
    "            out.loc[out[col].isna(), col] = 0.0\n",
    "    return out\n",
    "\n",
    "\n",
    "def impute_with_infinity(df):\n",
    "    out = pd.DataFrame(df)\n",
    "    for col in df.columns:\n",
    "        if col in num_cols:\n",
    "            out.loc[out[col].isna(), col] = float(\"inf\")\n",
    "    return out\n",
    "def impute_with_mode(df):\n",
    "    out = pd.DataFrame(df)\n",
    "    for col in df.columns:\n",
    "        if col in cat_cols:\n",
    "            out.loc[out[col].isna(), col] = df[col].mode().iat[0]\n",
    "    return out\n",
    "def impute_with_none(df):\n",
    "    out = pd.DataFrame(df)\n",
    "    for col in df.columns:\n",
    "        if col in cat_cols:\n",
    "            out.loc[out[col].isna(), col] = \"None\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impute_function(name):\n",
    "    assert name in [\"mean\", \"zero\", \"infinity\", \"mode\", \"none\"]\n",
    "    if name == \"mean\":\n",
    "        return impute_with_mean\n",
    "    elif name == \"zero\":\n",
    "        return impute_with_zero\n",
    "    elif name == \"infinity\":\n",
    "        return impute_with_infinity\n",
    "    elif name == \"mode\":\n",
    "        return impute_with_mode\n",
    "    else:\n",
    "        return impute_with_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(df, num_impute, cat_impute):\n",
    "    num_impute_function = get_impute_function(num_impute)\n",
    "    cat_impute_function = get_impute_function(cat_impute)\n",
    "    new_df = num_impute_function(df)\n",
    "    new_df = cat_impute_function(df)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                   0\n",
       "Sex                   0\n",
       "Job                   0\n",
       "Housing               0\n",
       "Duration              0\n",
       "Purpose               0\n",
       "Risk                  0\n",
       "Saving_accounts     183\n",
       "Checking_account    394\n",
       "Credit_amount         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = impute_missing_values(data, num_impute, cat_impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                 0\n",
       "Sex                 0\n",
       "Job                 0\n",
       "Housing             0\n",
       "Duration            0\n",
       "Purpose             0\n",
       "Risk                0\n",
       "Saving_accounts     0\n",
       "Checking_account    0\n",
       "Credit_amount       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      good\n",
       "1       bad\n",
       "2      good\n",
       "3      good\n",
       "4       bad\n",
       "       ... \n",
       "995    good\n",
       "996    good\n",
       "997    good\n",
       "998     bad\n",
       "999    good\n",
       "Name: Risk, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in cat_cols:\n",
    "#     data[col] = pd.Categorical(data[col])\n",
    "#     data[col] = data[col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      0\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "995    1\n",
      "996    1\n",
      "997    1\n",
      "998    0\n",
      "999    1\n",
      "Length: 1000, dtype: int8\n"
     ]
    }
   ],
   "source": [
    "data.Risk  = pd.Categorical(data.Risk)\n",
    "data.Risk = data.Risk.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scalers.json\", \"rb\") as input_file:\n",
    "    scalers = pickle.load(input_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in scalers:\n",
    "    data[col.replace(\" \", \"_\")] = scalers[col].transform(data[col.replace(\" \", \"_\")].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(data, test_size = 0.2, stratify=data.Risk, random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 10)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Sex', 'Job', 'Housing', 'Duration', 'Purpose', 'Risk',\n",
       "       'Saving_accounts', 'Checking_account', 'Credit_amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Saving_accounts</th>\n",
       "      <th>Checking_account</th>\n",
       "      <th>Credit_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.883041</td>\n",
       "      <td>male</td>\n",
       "      <td>skilled</td>\n",
       "      <td>own</td>\n",
       "      <td>-1.236478</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>1</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>-0.745131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.231145</td>\n",
       "      <td>female</td>\n",
       "      <td>skilled</td>\n",
       "      <td>own</td>\n",
       "      <td>2.248194</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>0</td>\n",
       "      <td>little</td>\n",
       "      <td>moderate</td>\n",
       "      <td>0.949817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.022283</td>\n",
       "      <td>male</td>\n",
       "      <td>unskilled and resident</td>\n",
       "      <td>own</td>\n",
       "      <td>-0.738668</td>\n",
       "      <td>education</td>\n",
       "      <td>1</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>-0.416562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.053225</td>\n",
       "      <td>male</td>\n",
       "      <td>skilled</td>\n",
       "      <td>free</td>\n",
       "      <td>1.750384</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>1</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>1.634247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.991340</td>\n",
       "      <td>male</td>\n",
       "      <td>skilled</td>\n",
       "      <td>free</td>\n",
       "      <td>0.256953</td>\n",
       "      <td>car</td>\n",
       "      <td>0</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>0.566664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age     Sex                     Job Housing  Duration  \\\n",
       "0 -2.883041    male                 skilled     own -1.236478   \n",
       "1 -3.231145  female                 skilled     own  2.248194   \n",
       "2 -3.022283    male  unskilled and resident     own -0.738668   \n",
       "3 -3.053225    male                 skilled    free  1.750384   \n",
       "4 -2.991340    male                 skilled    free  0.256953   \n",
       "\n",
       "               Purpose  Risk Saving_accounts Checking_account  Credit_amount  \n",
       "0             radio/TV     1          little           little      -0.745131  \n",
       "1             radio/TV     0          little         moderate       0.949817  \n",
       "2            education     1          little           little      -0.416562  \n",
       "3  furniture/equipment     1          little           little       1.634247  \n",
       "4                  car     0          little           little       0.566664  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('Risk')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = df_to_dataset(train_df, batch_size=32)\n",
    "val_ds = df_to_dataset(val_df, shuffle=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Sex', 'Job', 'Housing', 'Duration', 'Purpose', 'Risk',\n",
       "       'Saving_accounts', 'Checking_account', 'Credit_amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Credit_amount', 'Duration']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# numeric cols\n",
    "for feature in num_cols:\n",
    "    \n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex', 'Job', 'Housing', 'Saving_accounts', 'Checking_account', 'Purpose']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in cat_cols:\n",
    "    cat_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "      col_name, data[col_name].unique())\n",
    "    indicator_column = tf.feature_column.indicator_column(cat_column)\n",
    "    feature_columns.append(indicator_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(feature_columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "\n",
    "  layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_save = tf.keras.callbacks.ModelCheckpoint('keras-best-best-model.h5', save_weights_only=True, save_best_only=True, monitor='val_accuracy', mode=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_6 is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 1.4732 - accuracy: 0.3000 - val_loss: 1.4192 - val_accuracy: 0.3000\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3415 - accuracy: 0.3000 - val_loss: 1.2901 - val_accuracy: 0.3000\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2194 - accuracy: 0.3000 - val_loss: 1.1742 - val_accuracy: 0.3000\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1111 - accuracy: 0.3050 - val_loss: 1.0691 - val_accuracy: 0.3100\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0149 - accuracy: 0.3100 - val_loss: 0.9786 - val_accuracy: 0.3100\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.9327 - accuracy: 0.3212 - val_loss: 0.9002 - val_accuracy: 0.3250\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.8625 - accuracy: 0.3625 - val_loss: 0.8346 - val_accuracy: 0.3550\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.8044 - accuracy: 0.4250 - val_loss: 0.7802 - val_accuracy: 0.3750\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7575 - accuracy: 0.4763 - val_loss: 0.7346 - val_accuracy: 0.4900\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7184 - accuracy: 0.5500 - val_loss: 0.7000 - val_accuracy: 0.5550\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5750 - val_loss: 0.6713 - val_accuracy: 0.6150\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6162 - val_loss: 0.6504 - val_accuracy: 0.6650\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.6462 - val_loss: 0.6323 - val_accuracy: 0.7100\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.6713 - val_loss: 0.6186 - val_accuracy: 0.7050\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6813 - val_loss: 0.6096 - val_accuracy: 0.6950\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.6863 - val_loss: 0.6022 - val_accuracy: 0.7100\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.7000 - val_loss: 0.5966 - val_accuracy: 0.7050\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7063 - val_loss: 0.5917 - val_accuracy: 0.7000\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.7075 - val_loss: 0.5889 - val_accuracy: 0.7050\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.7087 - val_loss: 0.5866 - val_accuracy: 0.6950\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7063 - val_loss: 0.5852 - val_accuracy: 0.6900\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.7100 - val_loss: 0.5834 - val_accuracy: 0.7000\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7087 - val_loss: 0.5821 - val_accuracy: 0.7150\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.7075 - val_loss: 0.5816 - val_accuracy: 0.7100\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7075 - val_loss: 0.5807 - val_accuracy: 0.7100\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.7087 - val_loss: 0.5804 - val_accuracy: 0.7100\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7087 - val_loss: 0.5798 - val_accuracy: 0.7100\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7087 - val_loss: 0.5795 - val_accuracy: 0.7050\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.7075 - val_loss: 0.5791 - val_accuracy: 0.7050\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7087 - val_loss: 0.5789 - val_accuracy: 0.7100\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7100 - val_loss: 0.5784 - val_accuracy: 0.7100\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.7113 - val_loss: 0.5782 - val_accuracy: 0.7150\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.7100 - val_loss: 0.5782 - val_accuracy: 0.7050\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7100 - val_loss: 0.5777 - val_accuracy: 0.7050\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7087 - val_loss: 0.5776 - val_accuracy: 0.7050\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7087 - val_loss: 0.5773 - val_accuracy: 0.7100\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7100 - val_loss: 0.5770 - val_accuracy: 0.7100\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.7100 - val_loss: 0.5772 - val_accuracy: 0.7050\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7113 - val_loss: 0.5772 - val_accuracy: 0.7050\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7137 - val_loss: 0.5769 - val_accuracy: 0.7050\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7137 - val_loss: 0.5770 - val_accuracy: 0.7050\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7125 - val_loss: 0.5768 - val_accuracy: 0.7050\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7137 - val_loss: 0.5767 - val_accuracy: 0.7050\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7150 - val_loss: 0.5767 - val_accuracy: 0.7050\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7137 - val_loss: 0.5765 - val_accuracy: 0.7050\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7125 - val_loss: 0.5766 - val_accuracy: 0.7050\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7125 - val_loss: 0.5764 - val_accuracy: 0.7100\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7125 - val_loss: 0.5765 - val_accuracy: 0.7100\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7113 - val_loss: 0.5767 - val_accuracy: 0.7050\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7113 - val_loss: 0.5764 - val_accuracy: 0.7050\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7113 - val_loss: 0.5766 - val_accuracy: 0.7050\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7113 - val_loss: 0.5764 - val_accuracy: 0.7050\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7113 - val_loss: 0.5763 - val_accuracy: 0.7100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7113 - val_loss: 0.5765 - val_accuracy: 0.7100\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7125 - val_loss: 0.5765 - val_accuracy: 0.7100\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7125 - val_loss: 0.5767 - val_accuracy: 0.7100\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7125 - val_loss: 0.5768 - val_accuracy: 0.7100\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7125 - val_loss: 0.5767 - val_accuracy: 0.7050\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7125 - val_loss: 0.5768 - val_accuracy: 0.7050\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7137 - val_loss: 0.5769 - val_accuracy: 0.7050\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7175 - val_loss: 0.5770 - val_accuracy: 0.7000\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7175 - val_loss: 0.5766 - val_accuracy: 0.7000\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7175 - val_loss: 0.5769 - val_accuracy: 0.7000\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7175 - val_loss: 0.5770 - val_accuracy: 0.7000\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7175 - val_loss: 0.5770 - val_accuracy: 0.7000\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7175 - val_loss: 0.5771 - val_accuracy: 0.7000\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7175 - val_loss: 0.5772 - val_accuracy: 0.7000\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7188 - val_loss: 0.5773 - val_accuracy: 0.7000\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7175 - val_loss: 0.5772 - val_accuracy: 0.7000\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7188 - val_loss: 0.5774 - val_accuracy: 0.6950\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7212 - val_loss: 0.5776 - val_accuracy: 0.6950\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7212 - val_loss: 0.5778 - val_accuracy: 0.6900\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7238 - val_loss: 0.5778 - val_accuracy: 0.6900\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7225 - val_loss: 0.5780 - val_accuracy: 0.6900\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7225 - val_loss: 0.5779 - val_accuracy: 0.6900\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7250 - val_loss: 0.5778 - val_accuracy: 0.6900\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7200 - val_loss: 0.5781 - val_accuracy: 0.6900\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7238 - val_loss: 0.5782 - val_accuracy: 0.6900\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7262 - val_loss: 0.5784 - val_accuracy: 0.7000\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7250 - val_loss: 0.5784 - val_accuracy: 0.7000\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7238 - val_loss: 0.5783 - val_accuracy: 0.6900\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7250 - val_loss: 0.5784 - val_accuracy: 0.7000\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7250 - val_loss: 0.5788 - val_accuracy: 0.7050\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7250 - val_loss: 0.5788 - val_accuracy: 0.7050\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7250 - val_loss: 0.5790 - val_accuracy: 0.7000\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7238 - val_loss: 0.5789 - val_accuracy: 0.7050\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7250 - val_loss: 0.5790 - val_accuracy: 0.7050\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7288 - val_loss: 0.5793 - val_accuracy: 0.7050\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7250 - val_loss: 0.5793 - val_accuracy: 0.7050\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7262 - val_loss: 0.5793 - val_accuracy: 0.7050\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7262 - val_loss: 0.5795 - val_accuracy: 0.7050\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7262 - val_loss: 0.5796 - val_accuracy: 0.7050\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7275 - val_loss: 0.5796 - val_accuracy: 0.7050\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7275 - val_loss: 0.5799 - val_accuracy: 0.7100\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7275 - val_loss: 0.5798 - val_accuracy: 0.7050\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7238 - val_loss: 0.5798 - val_accuracy: 0.7100\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7250 - val_loss: 0.5799 - val_accuracy: 0.7100\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7250 - val_loss: 0.5802 - val_accuracy: 0.7150\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7262 - val_loss: 0.5800 - val_accuracy: 0.7100\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7250 - val_loss: 0.5804 - val_accuracy: 0.7150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc1d8b8ab70>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          callbacks=[mcp_save],\n",
    "          epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Credit_amount', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Duration', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Job', vocabulary_list=('skilled', 'unskilled and resident', 'highly skilled', 'unskilled and non-resident'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Housing', vocabulary_list=('own', 'free', 'rent'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Saving_accounts', vocabulary_list=('little', 'quite rich', 'rich', 'moderate'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Checking_account', vocabulary_list=('little', 'moderate', 'rich'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Purpose', vocabulary_list=('radio/TV', 'education', 'furniture/equipment', 'car', 'business', 'domestic appliances', 'repairs', 'vacation/others'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"keras-best-best-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"keras-best-model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"keras-best-model-weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mitiku/anaconda3/envs/tesf-env/lib/python3.6/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "inputs = np.stack(list(train_ds.take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(inputs[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       " array([-3.03775397, -3.20793792, -3.18473102, -3.10737468, -3.18473102,\n",
       "        -3.15378848, -2.89077692, -2.93719073, -3.20793792, -3.11511031,\n",
       "        -3.13831722, -3.21567356, -3.06096088, -2.91398383, -3.04548961,\n",
       "        -3.13058158, -3.14605285, -3.13831722, -3.18473102, -2.92171946,\n",
       "        -3.11511031, -3.20020229, -2.94492636, -3.23114483, -3.10737468,\n",
       "        -3.16152412, -3.13058158, -3.15378848, -2.94492636, -3.06869651,\n",
       "        -3.22340919, -3.20793792])>,\n",
       " 'Sex': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       " array([b'male', b'male', b'female', b'male', b'female', b'male', b'male',\n",
       "        b'male', b'female', b'female', b'male', b'female', b'male',\n",
       "        b'male', b'male', b'male', b'female', b'male', b'female', b'male',\n",
       "        b'male', b'male', b'female', b'female', b'male', b'female',\n",
       "        b'female', b'male', b'female', b'male', b'male', b'male'],\n",
       "       dtype=object)>,\n",
       " 'Job': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       " array([b'skilled', b'unskilled and resident', b'skilled', b'skilled',\n",
       "        b'skilled', b'skilled', b'highly skilled',\n",
       "        b'unskilled and resident', b'skilled', b'skilled', b'skilled',\n",
       "        b'skilled', b'highly skilled', b'skilled', b'skilled', b'skilled',\n",
       "        b'skilled', b'highly skilled', b'skilled', b'skilled', b'skilled',\n",
       "        b'skilled', b'skilled', b'unskilled and resident', b'skilled',\n",
       "        b'unskilled and resident', b'unskilled and resident', b'skilled',\n",
       "        b'skilled', b'skilled', b'unskilled and resident', b'skilled'],\n",
       "       dtype=object)>,\n",
       " 'Housing': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       " array([b'own', b'own', b'rent', b'free', b'own', b'own', b'own', b'own',\n",
       "        b'own', b'own', b'own', b'rent', b'rent', b'own', b'free', b'own',\n",
       "        b'own', b'free', b'rent', b'own', b'own', b'own', b'rent', b'own',\n",
       "        b'own', b'own', b'own', b'own', b'own', b'own', b'own', b'own'],\n",
       "       dtype=object)>,\n",
       " 'Duration': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       " array([-0.24085723, -0.9875727 ,  0.25695309,  0.25695309, -0.24085723,\n",
       "        -0.9875727 ,  0.75476341,  0.25695309,  0.75476341, -1.40241463,\n",
       "         0.25695309, -0.48976238, -1.23647786,  0.25695309, -0.90460432,\n",
       "         0.00804793, -0.24085723,  0.25695309, -0.48976238, -1.23647786,\n",
       "        -0.90460432, -0.73866754,  2.24819436, -0.48976238,  0.25695309,\n",
       "        -0.73866754,  2.16522598,  1.25257373, -0.48976238, -0.73866754,\n",
       "         0.50585825,  0.75476341])>,\n",
       " 'Purpose': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       " array([b'furniture/equipment', b'radio/TV', b'car', b'car',\n",
       "        b'furniture/equipment', b'radio/TV', b'business', b'car',\n",
       "        b'radio/TV', b'car', b'radio/TV', b'domestic appliances',\n",
       "        b'furniture/equipment', b'car', b'education',\n",
       "        b'furniture/equipment', b'car', b'car', b'car',\n",
       "        b'domestic appliances', b'domestic appliances', b'radio/TV',\n",
       "        b'business', b'business', b'car', b'furniture/equipment', b'car',\n",
       "        b'education', b'car', b'furniture/equipment', b'radio/TV',\n",
       "        b'business'], dtype=object)>,\n",
       " 'Saving_accounts': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       " array([b'little', b'little', b'rich', b'little', b'little', b'little',\n",
       "        b'little', b'little', b'little', b'little', b'rich', b'little',\n",
       "        b'little', b'little', b'quite rich', b'little', b'little',\n",
       "        b'little', b'moderate', b'quite rich', b'little', b'little',\n",
       "        b'little', b'little', b'moderate', b'little', b'little', b'little',\n",
       "        b'little', b'little', b'quite rich', b'little'], dtype=object)>,\n",
       " 'Checking_account': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       " array([b'little', b'little', b'little', b'rich', b'little', b'little',\n",
       "        b'rich', b'little', b'moderate', b'little', b'little', b'little',\n",
       "        b'little', b'little', b'little', b'moderate', b'moderate',\n",
       "        b'little', b'moderate', b'little', b'rich', b'little', b'moderate',\n",
       "        b'little', b'moderate', b'little', b'little', b'moderate',\n",
       "        b'little', b'little', b'moderate', b'little'], dtype=object)>,\n",
       " 'Credit_amount': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       " array([ 0.0534295 , -0.75611916, -0.23685962, -0.82381784, -0.51545211,\n",
       "        -0.20354194, -0.48319776, -0.73449811, -0.09933559,  0.03854288,\n",
       "        -0.2457207 , -0.70756042,  0.03996065, -0.1230833 , -0.90179538,\n",
       "         0.24979113, -0.79014572, -0.1280455 , -0.2269352 , -0.68523048,\n",
       "        -0.72528258, -0.47398223,  1.11463296, -0.87379436,  0.08532941,\n",
       "        -0.54416202,  2.64086612, -0.35382593,  0.62869109, -0.47362779,\n",
       "        -0.26627842,  1.70159118])>}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Credit_amount', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Duration', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Job', vocabulary_list=('skilled', 'unskilled and resident', 'highly skilled', 'unskilled and non-resident'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Housing', vocabulary_list=('own', 'free', 'rent'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Saving_accounts', vocabulary_list=('little', 'quite rich', 'rich', 'moderate'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Checking_account', vocabulary_list=('little', 'moderate', 'rich'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Purpose', vocabulary_list=('radio/TV', 'education', 'furniture/equipment', 'car', 'business', 'domestic appliances', 'repairs', 'vacation/others'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 1 layers into a model with 0 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-c0eadc9aa726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keras-best-model.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tesf-env/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    182\u001b[0m     if (h5py is not None and (\n\u001b[1;32m    183\u001b[0m         isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 184\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tesf-env/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tesf-env/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    683\u001b[0m                      \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                      \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                      ' layers.')\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m   \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 1 layers into a model with 0 layers."
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(\"keras-best-model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The layer has never been called and thus has no defined input shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-bffaa22f3275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tesf-env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36minput_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \"\"\"\n\u001b[1;32m   1847\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m       raise AttributeError('The layer has never been called '\n\u001b[0m\u001b[1;32m   1849\u001b[0m                            'and thus has no defined input shape.')\n\u001b[1;32m   1850\u001b[0m     all_input_shapes = set(\n",
      "\u001b[0;31mAttributeError\u001b[0m: The layer has never been called and thus has no defined input shape."
     ]
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['little', 'quite rich', 'rich', 'moderate'], dtype=object)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Saving_accounts\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['little', 'moderate', 'rich'], dtype=object)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Checking_account\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Sex', 'Job', 'Housing', 'Duration', 'Purpose', 'Risk',\n",
       "       'Saving_accounts', 'Checking_account', 'Credit_amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['own', 'free', 'rent'], dtype=object)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Housing.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tesf-env] *",
   "language": "python",
   "name": "conda-env-tesf-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
